{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e1pykJRn0qKQ"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWnk6WoK0qKR",
        "outputId": "974683c6-cac2-4639-c34a-7a1f0ac75da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (2.13.0rc1)\n",
            "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.13.0rc1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.2)\n",
            "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (58.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.54.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (6.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: finta in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (1.3)\n",
            "Requirement already satisfied: numpy in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from finta) (1.24.3)\n",
            "Requirement already satisfied: pandas in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from finta) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->finta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->finta) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->finta) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->finta) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (1.24.3)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.39.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: plotly==5.3.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (5.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from plotly==5.3.1) (8.2.2)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from plotly==5.3.1) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from opencv-python) (1.24.3)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: kaleido in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (0.2.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: autokeras in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (1.1.0)\n",
            "Requirement already satisfied: packaging in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from autokeras) (23.1)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from autokeras) (2.13.0rc1)\n",
            "Requirement already satisfied: keras-tuner>=1.1.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: keras-nlp>=0.4.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from autokeras) (0.5.2)\n",
            "Requirement already satisfied: pandas in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from autokeras) (2.0.2)\n",
            "Requirement already satisfied: absl-py in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from keras-nlp>=0.4.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: requests in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from keras-tuner>=1.1.0->autokeras) (1.0.5)\n",
            "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow>=2.8.0->autokeras) (2.13.0rc1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (4.23.2)\n",
            "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (58.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.54.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.13.0rc0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.13.1rc0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->autokeras) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pandas->autokeras) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2023.5.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.37.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.19.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (6.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (2.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow>=2.8.0->autokeras) (3.2.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting regex\n",
            "  Downloading regex-2023.6.3-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "Successfully installed regex-2023.6.3\n"
          ]
        }
      ],
      "source": [
        "# update tensorflow to 2.11.0\n",
        "!python3 -m pip install tensorflow\n",
        "!python3 -m pip install finta\n",
        "!python3 -m pip install -q --upgrade keras-nlp\n",
        "!python3 -m pip install numpy\n",
        "!python3 -m pip install pandas\n",
        "!python3 -m pip install matplotlib\n",
        "!pip install plotly==5.3.1\n",
        "!python3 -m pip install opencv-python\n",
        "!python3 -m pip install -U kaleido\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o8k9T-80qKT",
        "outputId": "559a3f13-d333-402d-eafe-b32c8f0e0d4e"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'AlbertClassifier' from partially initialized module 'keras_nlp.src.models.albert.albert_classifier' (most likely due to a circular import) (/Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/albert/albert_classifier.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreading\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mautokeras\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mak\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# from s3fs.core import S3FileSystem\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# s3 = S3FileSystem()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m0\u001b[39m)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/autokeras/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The AutoKeras Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautokeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto_model\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModel\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautokeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mblocks\u001b[39;00m \u001b[39mimport\u001b[39;00m BertBlock\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m \u001b[39mimport\u001b[39;00m samplers\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenizers\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/models/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_backbone\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertBackbone\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertClassifier\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_masked_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertMaskedLM\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_masked_lm_preprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertMaskedLMPreprocessor\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/albert/albert_classifier.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_backbone\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertBackbone\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_backbone\u001b[39;00m \u001b[39mimport\u001b[39;00m albert_kernel_initializer\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_preprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertPreprocessor\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_presets\u001b[39;00m \u001b[39mimport\u001b[39;00m backbone_presets\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m Task\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/albert/albert_preprocessor.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti_segment_packer\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiSegmentPacker\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_presets\u001b[39;00m \u001b[39mimport\u001b[39;00m backbone_presets\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_tokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertTokenizer\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m Preprocessor\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     convert_inputs_to_list_of_tensor_segments,\n\u001b[1;32m     25\u001b[0m )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/albert/albert_tokenizer.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_nlp_export\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_presets\u001b[39;00m \u001b[39mimport\u001b[39;00m backbone_presets\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msentence_piece_tokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m SentencePieceTokenizer\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m classproperty\n\u001b[1;32m     25\u001b[0m \u001b[39m@keras_nlp_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras_nlp.models.AlbertTokenizer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlbertTokenizer\u001b[39;00m(SentencePieceTokenizer):\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/__init__.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m samplers\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenizers\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2023 The KerasNLP Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_backbone\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertBackbone\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertClassifier\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_masked_lm\u001b[39;00m \u001b[39mimport\u001b[39;00m AlbertMaskedLM\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_nlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malbert_masked_lm_preprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     AlbertMaskedLMPreprocessor,\n\u001b[1;32m     20\u001b[0m )\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AlbertClassifier' from partially initialized module 'keras_nlp.src.models.albert.albert_classifier' (most likely due to a circular import) (/Users/joshuaattridge/Library/Python/3.9/lib/python/site-packages/keras_nlp/src/models/albert/albert_classifier.py)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import pandas as pd\n",
        "# import scipy.signal\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import io\n",
        "from finta import TA\n",
        "# import keras_nlp\n",
        "import random\n",
        "import os\n",
        "import threading\n",
        "# from s3fs.core import S3FileSystem\n",
        "# s3 = S3FileSystem()\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aiBJu2ly0qKW"
      },
      "source": [
        "# Gather Training Data\n",
        "classes:\n",
        "0 - no trend\n",
        "1 - short trend\n",
        "2 - long trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiTHUM_a0qKX",
        "outputId": "f15399b6-8a29-4a93-be04-9300d6e1338a"
      },
      "outputs": [],
      "source": [
        "candle_window_size = 200\n",
        "timeout_limit = 100\n",
        "# stoploss = 0.005\n",
        "risk_to_reward = 2\n",
        "\n",
        "def render(candle_data,SLDistance):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(\n",
        "        go.Candlestick(\n",
        "            open=candle_data[\"open\"],\n",
        "            high=candle_data[\"high\"],\n",
        "            low=candle_data[\"low\"],\n",
        "            close=candle_data[\"close\"], \n",
        "        )\n",
        "    )\n",
        "\n",
        "    # the candles are too thick for the image\n",
        "    fig.update_traces(\n",
        "        line=dict(width=1),\n",
        "        selector=dict(type=\"candlestick\")\n",
        "    )\n",
        "\n",
        "    # make the background white\n",
        "    fig.update_layout(\n",
        "        plot_bgcolor=\"white\",\n",
        "    )\n",
        "\n",
        "    # remove the legend\n",
        "    fig.update_layout(showlegend=False)\n",
        "\n",
        "    # add the stoploss lines\n",
        "    fig.add_shape(\n",
        "        dict(\n",
        "            type=\"line\",\n",
        "            x0=candle_window_size-1,\n",
        "            y0=candle_data[\"close\"].iloc[-1] + SLDistance,\n",
        "            x1=candle_window_size,\n",
        "            y1=candle_data[\"close\"].iloc[-1] + SLDistance,\n",
        "            line=dict(color=\"black\", width=1),\n",
        "        )\n",
        "    )\n",
        "    fig.add_shape(\n",
        "        dict(\n",
        "            type=\"line\",\n",
        "            x0=candle_window_size-1,\n",
        "            y0=candle_data[\"close\"].iloc[-1] - SLDistance,\n",
        "            x1=candle_window_size,\n",
        "            y1=candle_data[\"close\"].iloc[-1] - SLDistance,\n",
        "            line=dict(color=\"black\", width=1),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # the graph isnt going up to the edge of the image so make it go to the edge\n",
        "    fig.update_xaxes(range=[0, candle_window_size])\n",
        "\n",
        "    # remove small graph at the bottom\n",
        "    fig.update_layout(\n",
        "        xaxis=dict(\n",
        "            rangeslider=dict(\n",
        "                visible=False,\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    # remove white space around the graph\n",
        "    fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
        "    # remove the x and y axis\n",
        "    fig.update_xaxes(visible=False)\n",
        "    fig.update_yaxes(visible=False)\n",
        "\n",
        "    # lower the resolution of the image to 420p\n",
        "    fig.update_layout(width=len(candle_data), height=50)\n",
        "\n",
        "    # convert the plotly figure to a numpy array\n",
        "    fig_bytes = fig.to_image(format=\"png\")\n",
        "    buf = io.BytesIO(fig_bytes)\n",
        "    img = Image.open(buf)\n",
        "    img = np.asarray(img)\n",
        "    # convert the image to grayscale\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "    # if the colors in the image are not white then make them black\n",
        "    img[img < 255] = 0\n",
        "\n",
        "    # save the image\n",
        "    cv2.imwrite(\"render.png\", img)\n",
        "\n",
        "    # convert the image to bit data 1 or 0 instead of 0 or 255 then set the data type to boolean\n",
        "    img = img / 255\n",
        "    img = img.astype(np.int8)\n",
        "\n",
        "    return img\n",
        "\n",
        "# load data from data.npy\n",
        "try:\n",
        "    print(\"trying to load data from file\")\n",
        "    data = np.load('data.npy', allow_pickle=True)\n",
        "    results = np.load('results.npy', allow_pickle=True)\n",
        "\n",
        "    # only use the first 10000 data points\n",
        "    data = data[:10000]\n",
        "    results = results[:10000]\n",
        "\n",
        "except:\n",
        "    try:\n",
        "        print(\"trying to load data from s3\")\n",
        "        data_location = 's3://sagemakerforexaidata/data.npy'\n",
        "        results_location = 's3://sagemakerforexaidata/results.npy'\n",
        "        data = np.load(s3.open(data_location), allow_pickle=True)\n",
        "        results = np.load(s3.open(results_location), allow_pickle=True)\n",
        "    except Exception as e:\n",
        "        print(\"failed to load data creating new data\")\n",
        "        data = []\n",
        "        results = []\n",
        "\n",
        "# if data is empty, create a new one\n",
        "if len(data) == 0 or len(results) == 0:\n",
        "    # for each file in the data folder\n",
        "    cwd = os.getcwd()\n",
        "    path = os.path.join(cwd, 'data')\n",
        "    files = os.listdir(path)\n",
        "\n",
        "    for file in files:\n",
        "        chart_data = pd.read_csv(os.path.join(path, file))\n",
        "\n",
        "        # chart_data = chart_data.iloc[:3000].reset_index(drop=True) # remove this line to use the whole dataset\n",
        "        atr_multiplier = 1.5\n",
        "        chart_data['SLDistance'] = round(TA.ATR(chart_data, 14) * atr_multiplier,5)\n",
        "        chart_data.drop(['time'], axis=1, inplace=True)\n",
        "        chart_data = chart_data.iloc[500:].reset_index(drop=True)\n",
        "\n",
        "        def get_data_and_trend(candle_pos):\n",
        "            if candle_pos + timeout_limit > len(chart_data):\n",
        "                return\n",
        "\n",
        "            window_candle_data = chart_data[candle_pos-candle_window_size:candle_pos]\n",
        "            starting_price = window_candle_data['close'].iloc[-1]\n",
        "            SLDistance = window_candle_data['SLDistance'].iloc[-1]\n",
        "            hit_short_SL = False\n",
        "            hit_short_TP = False\n",
        "            hit_long_SL = False\n",
        "            hit_long_TP = False\n",
        "            for i in range(candle_pos+1, candle_pos + timeout_limit):\n",
        "                if chart_data['high'].iloc[i] > starting_price + SLDistance:\n",
        "                    hit_short_SL = True\n",
        "                if chart_data['low'].iloc[i] < starting_price - (SLDistance * risk_to_reward):\n",
        "                    hit_short_TP = True\n",
        "                    break\n",
        "                if chart_data['low'].iloc[i] < starting_price - SLDistance:\n",
        "                    hit_long_SL = True\n",
        "                if chart_data['high'].iloc[i] > starting_price + (SLDistance * risk_to_reward):\n",
        "                    hit_long_TP = True\n",
        "                    break\n",
        "            \n",
        "            trend = 0\n",
        "            if hit_short_SL == False and hit_short_TP == True:\n",
        "                # short trend\n",
        "                trend = 1\n",
        "            if hit_long_SL == False and hit_long_TP == True:\n",
        "                # long trend\n",
        "                trend = 2\n",
        "\n",
        "            rendered_data = render(window_candle_data, SLDistance)\n",
        "            data.append(rendered_data)\n",
        "            results.append(trend)\n",
        "\n",
        "            # add more data by flipping the rendered data upside down and reversing the trend\n",
        "            rendered_data = np.flip(rendered_data, 0)\n",
        "            if trend == 1:\n",
        "                trend = 2\n",
        "            elif trend == 2:\n",
        "                trend = 1\n",
        "            data.append(rendered_data)\n",
        "            results.append(trend)\n",
        "        \n",
        "        # run get_data_and_trend in parallel using threads\n",
        "        data_collection_threads = []\n",
        "        for candle_pos in range(candle_window_size, len(chart_data)):\n",
        "            try:\n",
        "                data_collection_threads.append(\n",
        "                    threading.Thread(target=get_data_and_trend, args=(candle_pos,))\n",
        "                )\n",
        "                data_collection_threads[-1].start()\n",
        "                progress = round((candle_pos / len(chart_data)) * 100, 2)\n",
        "                print(\"Thread Progress: \" + str(progress) + \"%\", end=\"\\r\")\n",
        "            # if failed to start a new thread then wait for all threads to finish and try again make sure to remove the threads that have finished\n",
        "            except:\n",
        "                for thread in data_collection_threads:\n",
        "                    # if thread has started then join it\n",
        "                    if thread.is_alive():\n",
        "                        thread.join()\n",
        "                data_collection_threads = []\n",
        "                data_collection_threads.append(\n",
        "                    threading.Thread(target=get_data_and_trend, args=(candle_pos,))\n",
        "                )\n",
        "                data_collection_threads[-1].start()\n",
        "                progress = round((candle_pos / len(chart_data)) * 100, 2)\n",
        "                print(\"Thread Progress: \" + str(progress) + \"%\", end=\"\\r\")\n",
        "\n",
        "        # wait for all threads to finish\n",
        "        for thread in data_collection_threads:\n",
        "            if thread.is_alive():\n",
        "                thread.join()\n",
        "        data_collection_threads = []\n",
        "\n",
        "        # create a text based progress bar that always stays on the same line and updates with percentage complete this must include both loops\n",
        "        progress = round((candle_pos / len(chart_data)) * 100, 2)\n",
        "        print(\"Progress: \" + str(progress) + \"%\", end=\"\\r\")\n",
        "            \n",
        "\n",
        "    data = np.array(data)\n",
        "    results = np.array(results)\n",
        "\n",
        "    # write the data to a file npy file that is zip compressed\n",
        "    np.save('data.npy', data, allow_pickle=True)\n",
        "    np.save('results.npy', results, allow_pickle=True)\n",
        "\n",
        "unique, counts = np.unique(results, return_counts=True)\n",
        "count_dict = dict(zip(unique, counts))\n",
        "\n",
        "print(\"Results:\")\n",
        "print(count_dict)\n",
        "\n",
        "# remove some of the data and results at random so all of the results have equal amounts\n",
        "min_count = min(counts)\n",
        "remove0 = count_dict[0] - min_count\n",
        "remove1 = count_dict[1] - min_count\n",
        "remove2 = count_dict[2] - min_count\n",
        "\n",
        "index_remove = []\n",
        "while remove0 > 0 or remove1 > 0 or remove2 > 0:\n",
        "    print(\"Removing: \" + str(remove0) + \" \" + str(remove1) + \" \" + str(remove2), end=\"\\r\")\n",
        "    index = random.randint(0, len(results)-1)\n",
        "    if index not in index_remove:\n",
        "        if results[index] == 0 and remove0 > 0:\n",
        "            index_remove.append(index)\n",
        "            remove0 -= 1\n",
        "        if results[index] == 1 and remove1 > 0:\n",
        "            index_remove.append(index)\n",
        "            remove1 -= 1\n",
        "        if results[index] == 2 and remove2 > 0:\n",
        "            index_remove.append(index)\n",
        "            remove2 -= 1\n",
        "\n",
        "data = np.delete(data, index_remove, axis=0)\n",
        "results = np.delete(results, index_remove, axis=0)\n",
        "\n",
        "# print the lenths of the data and results\n",
        "print(\"Data Length: \" + str(len(data)))\n",
        "print(\"Results Length: \" + str(len(results)))\n",
        "\n",
        "unique, counts = np.unique(results, return_counts=True)\n",
        "count_dict = dict(zip(unique, counts))\n",
        "\n",
        "print(\"Results:\")\n",
        "print(count_dict)\n",
        "\n",
        "# split the data into training and testing 30% testing and delete the original data to save memory\n",
        "training_data = data[:round(len(data)*0.7)]\n",
        "training_results = results[:round(len(results)*0.7)]\n",
        "testing_data = data[round(len(data)*0.7):]\n",
        "testing_results = results[round(len(results)*0.7):]\n",
        "del data\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ahIlkQBR0qKY"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoixs3KV0qKa",
        "outputId": "b3d8eb3c-e23a-42e5-aab9-2b11d4f4a7dd"
      },
      "outputs": [],
      "source": [
        "# create an advanced model that can predict forex chart trends based on the rendered images\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(len(training_data[0]),len(training_data[0][0]), 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(1,1), # decrease the size of the pooling window\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# create a custom metric to calculate the win rate of the model\n",
        "def win_rate(y_true, y_pred):\n",
        "    # convert y_pred to the max value of the array this needs to be done because the model returns an array of probabilities\n",
        "    y_pred = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    # convert the values to float32\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    # calculate the win rate of the model if the prediction is equal to the result and not equal to 0 then it is a win otherwise it is a loss\n",
        "    win_rate = tf.math.reduce_mean(tf.where(tf.math.logical_and(tf.math.equal(y_true, y_pred), tf.math.not_equal(y_pred, 0)), 1.0, 0.0))\n",
        "    return win_rate\n",
        "\n",
        "def forex_loss(y_true, y_pred):\n",
        "\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# create a adam optimizer with a custom learning rate \n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "model.compile(loss=forex_loss, optimizer=adam, metrics=[win_rate]) #remove accuracy metric on next run\n",
        "model.summary()\n",
        "\n",
        "early_stopping_val_win_rate = tf.keras.callbacks.EarlyStopping(monitor='win_rate', mode='max', patience=10, restore_best_weights=True)\n",
        "\n",
        "# create some class weights so guessing class 1 and 2 correctly is more important than guessing class 0 correctly\n",
        "class_weight = {0: 0.5, 1: 1, 2: 1}\n",
        "\n",
        "# train the model\n",
        "model.fit(training_data, training_results, epochs=1000, batch_size=128, validation_data=(testing_data, testing_results), callbacks=[early_stopping_val_win_rate])\n",
        "\n",
        "# save the model\n",
        "model.save(\"model_\" + str(round(max(model.history.history['val_win_rate']) * 100, 2)) + \"_winrate.h5\")\n",
        "\n",
        "# plot the training and validation win rate\n",
        "plt.plot(model.history.history['win_rate'])\n",
        "plt.plot(model.history.history['val_win_rate'])\n",
        "plt.title('Model Win Rate')\n",
        "plt.ylabel('Win Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "# write plot to file\n",
        "plt.savefig(\"model_\" + str(round(max(model.history.history['val_win_rate']) * 100, 2)) + \"_winrate.png\", format='png')\n",
        "\n",
        "# plot the training and validation loss\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "# write plot to file\n",
        "plt.savefig(\"model_\" + str(round(max(model.history.history['val_win_rate']) * 100, 2)) + \"_loss.png\", format='png')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u378jnbT0qKb"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEEJ6myH0qKb"
      },
      "outputs": [],
      "source": [
        "# test the model on the testing data\n",
        "test_loss, test_win_rate = model.evaluate(testing_data, testing_results, verbose=2)\n",
        "print(\"Test Loss: \" + str(test_loss))\n",
        "print(\"Test Win Rate: \" + str(test_win_rate))\n",
        "\n",
        "# make a prediction for each of the testing data\n",
        "predictions = model.predict(np.array(testing_data))\n",
        "# print the first 10 predictions\n",
        "print(\"Predictions:\")\n",
        "for i in range(10):\n",
        "    print(predictions[i])\n",
        "\n",
        "# compare the predictions to the actual results for each class (no trend, short trend, long trend) and display the results\n",
        "\n",
        "win_confidence_tracker = []\n",
        "loss_confidence_tracker = []\n",
        "\n",
        "classes = [\"No Trend\", \"Short Trend\", \"Long Trend\"]\n",
        "for i in range(1,3):\n",
        "    for j in range(len(predictions)):\n",
        "        if np.argmax(predictions[j]) == i:\n",
        "            if np.argmax(predictions[j]) == testing_results[j]:\n",
        "                win_confidence_tracker.append(predictions[j][i])\n",
        "            else:\n",
        "                loss_confidence_tracker.append(predictions[j][i])\n",
        "\n",
        "# print the amount of times the model picked a class\n",
        "print(\"No Trend: \" + str(len([x for x in predictions if np.argmax(x) == 0])))\n",
        "print(\"Short Trend: \" + str(len([x for x in predictions if np.argmax(x) == 1])))\n",
        "print(\"Long Trend: \" + str(len([x for x in predictions if np.argmax(x) == 2])))\n",
        "\n",
        "\n",
        "# print the win rate\n",
        "print(\"Win Rate: \" + str(round(len(win_confidence_tracker) / (len(win_confidence_tracker) + len(loss_confidence_tracker)) * 100, 2)) + \"%\")\n",
        "# print risk to reward ratio\n",
        "print(\"Risk to Reward Ratio: \" + str(risk_to_reward))\n",
        "# print the highest confidence of the correct predictions\n",
        "print(\"Highest Correct Confidence: \" + str(round(max(win_confidence_tracker) * 100, 2)) + \"%\")\n",
        "# print the lowest confidence of the correct predictions\n",
        "print(\"Lowest Correct Confidence: \" + str(round(min(win_confidence_tracker) * 100, 2)) + \"%\")\n",
        "# print the highest incorrect confidence\n",
        "print(\"Highest Incorrect Confidence: \" + str(round(max(loss_confidence_tracker) * 100, 2)) + \"%\")\n",
        "# print the lowest incorrect confidence\n",
        "print(\"Lowest Incorrect Confidence: \" + str(round(min(loss_confidence_tracker) * 100, 2)) + \"%\")\n",
        "\n",
        "plt.hist(win_confidence_tracker, bins=100, alpha=0.5, label='Correct')\n",
        "plt.hist(loss_confidence_tracker, bins=100, alpha=0.5, label='Incorrect')\n",
        "plt.legend(loc='upper right')\n",
        "# write plot to file\n",
        "plt.savefig(\"model_\" + str(round(max(model.history.history['val_win_rate']) * 100, 2)) + \"_confidence.png\", format='png')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
